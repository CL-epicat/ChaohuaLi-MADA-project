---
title: "Formal analysis script for the MADA project"
author: "Chaohua Li"
date: "`r Sys.Date()`"
output: html_document
---

The codes in the file are for the formal analysis. All results will be included in the
final manuscript. 

# Load packages

```{r}
library(here)  
library(dplyr)
library(skimr)
library(ggplot2)
library(gtsummary)
library(knitr)
library(table1)
library(lme4)
library(jtools) 
library(rsample)
library(tidymodels)
library(multilevelmod)
library(randomForest)
library(randomForestExplainer)
library(sjtable2df)
``` 
  
  
# Load the clean data.

```{r}
data_location <- here("data","processed-data","processeddata.rds")
project <- readRDS(data_location)
``` 
  

# Create Table 1 (descriptive statistics)
```{r}
#create a publication-ready table 1
descriptive_table<-table1(~ . | metro , data=project[, !(names(project) %in% c("state", "TL_GEO_ID"))],topclass="Rtable1-zebra")

#save table in results folder
table1path = here("results","analysis", "table1.rds")
saveRDS(descriptive_table, file = table1path)
```
  
  
# Create Figure 1 (scatterplot of mortality rate and log(PCP supply))
```{r}
#scatterplot by metro status
figure1 <- project %>%
  ggplot(aes(x = log(pcp_100k), y = Rate2)) +
  geom_point() +
  geom_smooth(method = 'lm') +
  facet_wrap(~ metro, scales = "free_y") +
  xlab("Log(PCP per 100k)") + 
  ylab("Mortality rate, n/100k")  

# Plot the ggplot object
plot(figure1)
#save figure in result folder
figure1path = here("results","analysis","figure1.png")
ggsave(filename = figure1path, plot=figure1) 

```
  
  
  
# Calculate Intra-class correlation(ICC) from the unconditional means model to decide whether a multi-level linear model with random intercepts for states is necessary. 
```{r}
#fit an unconditional means model with random intercepts for states
fit0<-lmer(Rate2 ~ 1 + (1 | state), data=project)
#calculate ICC
VarCorr(fit0)
RandomEffects <- as.data.frame(VarCorr(fit0))
ICC_between <- RandomEffects[1,4]/(RandomEffects[1,4]+RandomEffects[2,4]) 
ICC_between
``` 

ICC=0.232. This indicates 23.2% of total variance in county-level mortality rates 
is attributable to between state variation, and the rest of the 76.8% is attributable 
to the within-state variation. A multilevel linear model with random intercepts 
for states is preferred to analysis the association between mortality rates and PCP supply. 
  

# Fit bivariate multilevel models with mortality rate as the outcome
Since distribution of PCP supply is highly skewed, we need to log transform it. 
PCP supply will be in the form of log(pcp_100k+0.01). Adding 0.01 to the PCP supply 
value for each county is because some counties have 0 PCP supply and cannot be log transformed.
```{r}
#fit bivariate multilevel models with each predictor
fit1<-lme4::lmer(Rate2 ~ log(pcp_100k+0.01) + (1 | state), data=project)
fit2<-lme4::lmer(Rate2 ~ metro + (1 | state), data=project)
fit3<-lme4::lmer(Rate2 ~ hispanic_pct + (1 | state), data=project)
fit4<-lme4::lmer(Rate2 ~ NHB_pct + (1 | state), data=project)
fit5<-lme4::lmer(Rate2 ~ noHS_pct + (1 | state), data=project)
fit6<-lme4::lmer(Rate2 ~ poverty_pct + (1 | state), data=project)
fit7<-lme4::lmer(Rate2 ~ unemployed_pct + (1 | state), data=project)
fit8<-lme4::lmer(Rate2 ~ uninsured_pct + (1 | state), data=project)

#summary of results
summ(fit1)
summ(fit2)
summ(fit3)
summ(fit4)
summ(fit5)
summ(fit6)
summ(fit7)
summ(fit8)


library(sjPlot) # table functions
#combine results from every two models into a single table
table2a<-tab_model(fit1, fit2,show.icc = FALSE,show.re.var = FALSE,show.aic = TRUE,digits = 1,digits.p = 3)
table2aa <- sjtable2df::mtab2df(mtab = table2a, n_models =2) #convert html table to a dataframe

table2b<-tab_model(fit3, fit4,show.icc = FALSE,show.re.var = FALSE,show.aic = TRUE,digits = 1,digits.p = 3)
table2bb <- sjtable2df::mtab2df(mtab = table2b, n_models =2) #convert html table to a dataframe

table2c<-tab_model(fit5, fit6,show.icc = FALSE,show.re.var = FALSE,show.aic = TRUE,digits = 1,digits.p = 3)
table2cc <- sjtable2df::mtab2df(mtab = table2c, n_models =2) #convert html table to a dataframe

table2d<-tab_model(fit7, fit8,show.icc = FALSE,show.re.var = FALSE,show.aic = TRUE,digits = 1,digits.p = 3)
table2dd <- sjtable2df::mtab2df(mtab = table2d, n_models =2) #convert html table to a dataframe

#save the 4 tables in results folder
table2apath = here("results","analysis", "table2a.rds")
saveRDS(table2aa, file = table2apath)

table2bpath = here("results","analysis", "table2b.rds")
saveRDS(table2bb, file = table2bpath)

table2cpath = here("results","analysis", "table2c.rds")
saveRDS(table2cc, file = table2cpath)

table2dpath = here("results","analysis", "table2d.rds")
saveRDS(table2dd, file = table2dpath)

```
  
  
# Create a dataframe for fitting the multivariate model
```{r}
#add log-transformed PCP, and drop county id and original pcp variable
final_data<-project %>%
  mutate(log_PCP=log(pcp_100k+0.01)) %>%
  select(-TL_GEO_ID)

#save dataset to processed-data folder
save_data_location <- here("data","processed-data","final_data.rds")
saveRDS(final_data, file = save_data_location)
``` 
  
  
# Split the data randomly into a 80% train set and a 20% test set.
  The train set will be used for fitting the model. The test set will be used for 
  final evaluation of the model performance. 
```{r}
#save a seed value
rngseed = 1234

#set the seed
set.seed(rngseed)

#splits the dataset randomly into a 80% train set and a 20% test set
data_split <- initial_split(final_data, prop = 4/5)
train_data <- training(data_split)
test_data  <- testing(data_split)
``` 
  
  
# Fit 3 models and evaluate performance using 10-fold cross-validation. 
  Model 1: linear mixed effect model: log_PCP as the only predictor;
  
  Model 2: linear mixed effect model: log_PCP and all covariates;
  
  Model 3: random forest model; predictors = PCP and all covariates; number of trees=100
  
## create 10-foler cross-validation sets
```{r}
#reset the seed
set.seed(rngseed)

#10 folder Cross-validation
folds <- vfold_cv(train_data, v = 10)
``` 


## Fit Model 1: linear mixed effect model: log_PCP as the only predictor
```{r}
#specify linear mixed effect model
lmer_spec <- 
  linear_reg() %>% 
  set_engine("lmer")

#create workflow for Model 1 with log_PCP as the only predictor
flow_1 <- 
  workflow() %>% 
  add_variables(outcomes = Rate2, predictors = c(log_PCP ,state)) %>% 
  add_model(lmer_spec, formula = Rate2 ~ log_PCP + (1|state))

#Fit Model 1
set.seed(rngseed)
fit_cv_1 <- 
  flow_1 %>% 
  fit_resamples(folds)

#get RMSE of the model
collect_metrics(fit_cv_1)
``` 


## Fit Model 2: linear mixed effect model: log_PCP and all covariates.
```{r}
#create workflow for Model 3 with log_PCP and all covariates
flow_2 <- 
  workflow() %>% 
  add_variables(outcomes = Rate2, predictors = c(log_PCP,metro,hispanic_pct,NHB_pct,
                                                 noHS_pct, poverty_pct, unemployed_pct,
                                                 uninsured_pct, state)) %>% 
  add_model(lmer_spec, formula = Rate2 ~ log_PCP+metro+hispanic_pct+NHB_pct+
                                                 noHS_pct+ poverty_pct+ unemployed_pct+
                                                 uninsured_pct + (1|state))

#Fit Model 2
set.seed(rngseed)
fit_cv_2 <- 
  flow_2 %>% 
  fit_resamples(folds)

#get RMSE of the model
collect_metrics(fit_cv_2)
``` 

## Fit Model 3: random forest model; predictors = PCP and all covariates; number of trees=100
```{r}
library(ranger)
#random Forest model specification
rf_spec <- rand_forest(trees = 100) %>%  # using 100 trees
  set_engine("ranger") %>%
  set_mode("regression")

#workflow creation
rf_workflow <- workflow() %>%
  add_formula(Rate2 ~pcp_100k +metro+hispanic_pct+NHB_pct+ noHS_pct+ poverty_pct
              + unemployed_pct+ uninsured_pct + state) %>%
  add_model(rf_spec)

#model fitting and evaluation
set.seed(rngseed)
fit_rf <- fit_resamples(
  rf_workflow,
  folds,
  control = control_resamples(save_pred = TRUE)
)

#print the performance of model(RMSE, R-squared)
results_rf <- collect_metrics(fit_rf)
print(results_rf)
```
  

  Model 1: log_PCP as the only predictor - RMSE=358, R-squared=0.05
  
  Model 2: log_PCP and all covariates    - RMSE=292, R-squared=0.37
  
  Model 3: Random Forest Model           - RMSE=248, R-squared=0.54.

The random forest model has better performance than either of the linear mixed effect models. 



## Fit Model 1, Model 2 and Model 3 with the train set, and create predicted vs observed values plot

Fit Model 1, Model 2 and Model 3 with train set.
```{r}
#Fit Model 1 with train set
fit_train_1<-lme4::lmer(Rate2 ~ log_PCP + (1|state), data=train_data)

#Fit Model 2 with train set
fit_train_2<-lme4::lmer(Rate2 ~ log_PCP+metro+hispanic_pct+NHB_pct+
                                noHS_pct+ poverty_pct+ unemployed_pct+
                                uninsured_pct + (1|state), data=train_data)

#Fit Model 3 with train set
set.seed(rngseed)
rf_fit <- fit(rf_workflow, data = train_data)
``` 
  
  
Generate predictions for the models.
```{r}
# Prediction for Model 1 (log_PCP as predictor)
pred1 <- predict(fit_train_1, newdata=train_data) 
pred1<-data.frame(Observed=train_data$Rate2,Predicted=pred1,Model="Model 1: Log(PCP) only")


# Prediction for Model 2 (log_PCP and all covariates)
pred2 <- predict(fit_train_2, newdata=train_data) 
pred2<-data.frame(Observed=train_data$Rate2,Predicted=pred2,Model="Model 2: All predictors")

# Prediction for Model 3
pred3 <- predict(rf_fit, new_data=train_data) 
pred3<-data.frame(Observed=train_data$Rate2,Predicted=pred3$.pred,Model="Model 3: Random Forest")

# Concatenate the predictions into one dataframe
combined_predictions <- bind_rows(pred1, pred2, pred3)
``` 
  
  
Plot Predicted vs Observed values for both models
```{r}
#Plot predicted vs observed values by models
predict_plot<-ggplot(combined_predictions, aes(x = Observed, y = Predicted, color = Model)) +
  geom_point( alpha=0.5) +  
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "grey") +  
  labs(x = "Observed Values", y = "Predicted Values", title = "Observed vs. Predicted Values by Models", color = "Model") +
  theme_minimal() + # Use a minimal theme for aesthetics
  scale_shape_manual(values = c( 17, 18, 19)) + # Set different shapes for each level of the label variable
  scale_color_manual(values = c( "green", "blue","red"))
plot(predict_plot)

#save plot 
predict_path = here("results","analysis","predict_observed.png")
ggsave(filename = predict_path, plot=predict_plot) 
```  

Plot residuals vs predicted values by models
```{r}
#calculate residuals
combined_predictions <- combined_predictions %>%
  mutate(residuals = Predicted - Observed)

#Plot residuals vs predicted values by models
residual_plot<-ggplot(combined_predictions, aes(x = Predicted, y = residuals, color = Model)) +
  geom_point(alpha=0.5) +  
  geom_abline(slope = 0, intercept = 0, linetype = "dashed", color = "grey") +  
  labs(x = "Predicted Values", y = "Residuals", title = "Residuals vs. Predicted Values by Models", color = "Model") +
  theme_minimal() + # Use a minimal theme for aesthetics
  scale_shape_manual(values = c( 17, 18)) + # Set different shapes for each level of the label variable
  scale_color_manual(values = c( "green", "blue","red"))
plot(residual_plot)

#Save plot
residual_path = here("results","analysis","residual_plot.png")
ggsave(filename = residual_path, plot=residual_plot) 
```  

For Model 3, the data points are generally scattered around the diagonal line and the predicted values are closer to the observed values than the data points for Model 1 and Model 2. Thus, the random forest model can predict the outcome better than the other two models.

But since the random forest model results are not as interpretable as the results from linear mixed effect models, I decide to report results for both model 2(linear mixed effect model) and model 3 (random forest). The point of reporting results from model 2 is that the parameter estimates can tell us how the mortality rate is related to the PCP supply. 


# Retrieve model results for Model 2
```{r}
#Model results
summ(fit_train_2)

#Save results to a dataframe
table_model<-tab_model(fit_train_2,show.icc = FALSE,show.re.var = FALSE,show.aic = TRUE,digits = 1,digits.p = 3)
table_model_data <- sjtable2df::mtab2df(mtab = table_model, n_models =1) #convert html table to a dataframe

#Save the result table in results folder
tablepath = here("results","analysis", "Model_result.rds")
saveRDS(table_model_data, file = tablepath)
```  
  

# Retrieve model results for Model 3
```{r}
#Model results
set.seed(rngseed)
rf_result <- randomForest(Rate2 ~pcp_100k +metro+hispanic_pct+NHB_pct+ noHS_pct+ poverty_pct + unemployed_pct+ uninsured_pct + state, data=train_data, ntree=100, keep.forest=FALSE, importance=TRUE)
rf_result

#importance table for Random Forest
import_table<-randomForest::importance(rf_result)
import_table
#save the table to a rds file
importance_path = here("results","analysis", "importance.rds")
saveRDS(import_table, file = importance_path)
```  


# Apply models to the test set

## Model 2
Calculate predictions using the test set. 
```{r}
# Make predictions using test set
pred_test <- predict(fit_train_2, newdata = test_data)
pred_test<-data.frame(Observed=test_data$Rate2,Predicted=pred_test,Model="Test Set")


# Prediction based on train set
pred_train<-data.frame(Observed=train_data$Rate2,Predicted=pred2$Predicted,Model="Train Set")


# Concatenate the predictions into one dataframe
train_test <- bind_rows(pred_test, pred_train)
```  


Plot predicted versus observed values for both the train data and test data
```{r}
#Plot predicted versus observed values by train/test data
train_test_plot<-ggplot(train_test, aes(x = Observed, y = Predicted, color  = Model, shape=Model)) +
  geom_point( alpha=0.5) +  
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "grey") +  
  labs(x = "Observed Values", y = "Predicted Values", title = "Observed vs. Predicted Values by Train/Test data", color = "Train/Test Data", shape ="Train/Test Data" ) +
  theme_minimal() + # Use a minimal theme for aesthetics
  scale_shape_manual(values = c(15, 17)) + # Set different shapes for train/test predictions
  scale_color_manual(values = c("blue", "green"))

plot(train_test_plot)

#Save plot
train_test_path = here("results","analysis","train_test_plot.png")
ggsave(filename = train_test_path, plot=train_test_plot)
```  
The data points on the observed vs predicted plot using the test data scatter around the diagonal line, which indicates the predictions on the test data are generally accurate. 


## Model 3
Calculate predictions using the test set. 
```{r}
# Make predictions using test set
pred3_test <- predict(rf_fit, new_data=test_data) 
pred3_test<-data.frame(Observed=test_data$Rate2,Predicted=pred3_test$.pred,Model="Test Set")


# Prediction based on train set
pred3_train<-data.frame(Observed=train_data$Rate2,Predicted=pred3$Predicted,Model="Train Set")


# Concatenate the predictions into one dataframe
train_test3 <- bind_rows(pred3_test, pred3_train)
```  


Plot predicted versus observed values for both the train data and test data
```{r}
#Plot predicted versus observed values by train/test data
train_test_plot2<-ggplot(train_test3, aes(x = Observed, y = Predicted, color  = Model, shape=Model)) +
  geom_point( alpha=0.5) +  
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "grey") +  
  labs(x = "Observed Values", y = "Predicted Values", title = "Observed vs. Predicted Values by Train/Test data", color = "Train/Test Data", shape ="Train/Test Data" ) +
  theme_minimal() + # Use a minimal theme for aesthetics
  scale_shape_manual(values = c(15, 17)) + # Set different shapes for train/test predictions
  scale_color_manual(values = c("blue", "green"))

plot(train_test_plot2)

#Save plot
train_test_path2 = here("results","analysis","train_test_plot2.png")
ggsave(filename = train_test_path2, plot=train_test_plot2)
```  
The data points on the observed vs predicted plot using the test data scatter around the diagonal line very closely, which indicates the predictions on the test data are fairly accurate.


